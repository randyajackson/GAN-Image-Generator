{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator and Discriminator\n",
    "#Generator makes fakes and Discriminator decides if real or fake\n",
    "\n",
    "#Building the discriminator\n",
    "#Discriminator is 1 for black and 0 for white in a 2x2 image. \n",
    "#The difference between the Discriminator values and the noise values is the threshold.\n",
    "#Top left and bottom right are positive, the rest are negative.\n",
    "#Perfect would be top left / bottom right 1, the rest 0\n",
    "#Example [Discriminator Total] 1*1 + 0*(-1) + 0*(-1) + 1*1 = 2\n",
    "#[Noise Total] .25*1 + 1 * (-1) + .5 *(-1) + .75 * 1 = -.5\n",
    "#The bias is 1 (subtracted) so Discriminator total is 1 and Noise total is -1.5\n",
    "#If the threshold is more than 1, then it is real.\n",
    "#Sigmoid of 1 is .73 so since 73% chance that it is real is above 50% it's considered real.\n",
    "#Sigmoid of -1.5 is .18 so 18% chance it is real is less than 50% consider it a fake.\n",
    "\n",
    "# Building a generator\n",
    "# In generators we want the bias to be high in top left and bottom right (+1) and low in the others (-1)\n",
    "# Random numbers between 0 and 1 are assigned to all 4 cells but the bias is added.\n",
    "# Example values 1.7, -1.7, 1.7, -1.7 and the sigmoids of these values show .85 and .15\n",
    "# The generator has to learn to apply this bias to get a desired result\n",
    "# Error functions - different error functions can be applied this example uses log loss error function\n",
    "\n",
    "# If label is 1 (desired result) and prediction is .1 that's a large error.\n",
    "# If label is 1 (desired result) and prediction is .9 that's a small error.\n",
    "# Negative log of the prediction number is the error. -ln(.1) = 2.3 and -ln(.9) = .1\n",
    "\n",
    "# If label is 0 (non-desired result) and prediction is .9 that's a large error.\n",
    "# If label is 0 (non-desired result) and prediction is .1 that's a small error.\n",
    "# Negative log of (1 - prediction number) is the error. -ln( 1 - .9) = 2.3 and -ln(1 - .9) = .1\n",
    "\n",
    "#Backpropagation - reduces the error amount as it progresses through the model.\n",
    "\n",
    "#Whole process is the generator creates noise and creates and image then passes it to the discriminator which \n",
    "#calculates a sigmoid and checks if real or fake.\n",
    "#The generators goal is to be closer to 1 using -ln(.68) and the discriminator's goal is being closer to 0 with -ln(1 - .68).\n",
    "#The error functions are updated exclusive to the 2 models because of this making both better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33cdd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ed5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to normalize the 3 RGB values to a single value between -1 and 1 to increase computing time.\n",
    "#stats = this is the mean (0.5, 0.5, 0.5), this is the standard deviation(0.5, 0.5, 0.5)\n",
    "\n",
    "#There's around 5000 images.\n",
    "#The batch size are the number of samples that will be propagated through the network before updating the model parameters.\n",
    "#Consider RAM/GPU limitations with the pixel size.\n",
    "#Larger batch sizes result in faster progress in training, but don't always converge as fast.\n",
    "#Smaller batch sizes train slower, but can converge faster.\n",
    "#Converging meaning getting a stable value.\n",
    "#32 or 64 is a good starting point\n",
    "\n",
    "DATA_DIR = '/home/development/Desktop/First GAN Project/GAN Image Generator/GAN-Image-Generator/animal-faces/afhq/dog/'\n",
    "batch_size = 32\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444125db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When arranging the data, the DATA_DIR needs to be the root with the data as sub folders. (ex: I had to create a 'Dog' subdirectory.)\n",
    "#Tensor has a different meaning in ML versus math.\n",
    "#Tensors allow for GPU acceleration.\n",
    "#Tensors hold the data, weights, and biases. They take care of backpropogation with automatic differentiation.\n",
    "#An image is a 2D array of height x width containing 3 channels for RGB.\n",
    "#ToTensor normalizes the 3 channels to be within 0-1 for each channel.\n",
    "#shuffle - Randomize the data being loaded or not\n",
    "#num_workers - Turn on multi-process data loading with the specified number of loader worker processes\n",
    "#pin_memory - Enables fast data transfer to CUDA-enabled GPUs\n",
    "\n",
    "train_ds = ImageFolder(DATA_DIR, transform=T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*stats)]))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
